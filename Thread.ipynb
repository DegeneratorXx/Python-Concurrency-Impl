{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58d8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89eda2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def thread_function(name):\n",
    "    logging.info(\"Thread %s: starting\", name)\n",
    "    time.sleep(2)\n",
    "    logging.info(\"Thread %s: finishing\", name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd53e1",
   "metadata": {},
   "source": [
    "## Single Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37e3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:36: Main    : before creating thread\n",
      "13:41:36: Main    : before running thread\n",
      "13:41:36: Thread 1: starting\n",
      "13:41:36: Main    : wait for the thread to finish\n",
      "13:41:36: Main    : all done\n",
      "13:41:36: Main    : before running thread\n",
      "13:41:36: Thread 1: starting\n",
      "13:41:36: Main    : wait for the thread to finish\n",
      "13:41:36: Main    : all done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:38: Thread 1: finishing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\" # setup logging format\n",
    "\n",
    "    logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")  # setup logging\n",
    "\n",
    "    logging.info(\"Main    : before creating thread\")\n",
    "    x = threading.Thread(target=thread_function, args=(1,))\n",
    "    logging.info(\"Main    : before running thread\")\n",
    "    x.start() # start the thread\n",
    "    logging.info(\"Main    : wait for the thread to finish\")\n",
    "    # x.join()\n",
    "    logging.info(\"Main    : all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665b6f6",
   "metadata": {},
   "source": [
    "## Daemon Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f06e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:38: Main    : before creating thread\n",
      "13:41:38: Main    : before running thread\n",
      "13:41:38: Thread 1: starting\n",
      "13:41:38: Main    : wait for the thread to finish\n",
      "13:41:38: Main    : all done\n",
      "13:41:38: Main    : before running thread\n",
      "13:41:38: Thread 1: starting\n",
      "13:41:38: Main    : wait for the thread to finish\n",
      "13:41:38: Main    : all done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:40: Thread 1: finishing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\" # setup logging format\n",
    "\n",
    "    logging.basicConfig(format=format, level=logging.INFO,datefmt=\"%H:%M:%S\")  # setup logging\n",
    "\n",
    "    logging.info(\"Main    : before creating thread\")\n",
    "    x = threading.Thread(target=thread_function, args=(1,), daemon=True)\n",
    "    logging.info(\"Main    : before running thread\")\n",
    "    x.start() # start the thread\n",
    "    logging.info(\"Main    : wait for the thread to finish\")\n",
    "    # x.join()\n",
    "    logging.info(\"Main    : all done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5c46cf",
   "metadata": {},
   "source": [
    "## Multiple Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b93cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:40: START CREATING THREADS\n",
      "13:41:40: create and start thread 0\n",
      "13:41:40: Thread 0: starting\n",
      "13:41:40: create and start thread 1\n",
      "13:41:40: Thread 1: starting\n",
      "13:41:40: create and start thread 2\n",
      "13:41:40: Thread 2: starting\n",
      "13:41:40: all threads started\n",
      "13:41:40: ENDING THE THREADS\n",
      "13:41:40: before joining thread 0\n",
      "13:41:40: create and start thread 0\n",
      "13:41:40: Thread 0: starting\n",
      "13:41:40: create and start thread 1\n",
      "13:41:40: Thread 1: starting\n",
      "13:41:40: create and start thread 2\n",
      "13:41:40: Thread 2: starting\n",
      "13:41:40: all threads started\n",
      "13:41:40: ENDING THE THREADS\n",
      "13:41:40: before joining thread 0\n",
      "13:41:42: Thread 0: finishing\n",
      "13:41:42: Thread 2: finishing\n",
      "13:41:42: Thread 1: finishing\n",
      "13:41:42: thread 0 done\n",
      "13:41:42: before joining thread 1\n",
      "13:41:42: thread 1 done\n",
      "13:41:42: before joining thread 2\n",
      "13:41:42: thread 2 done\n",
      "13:41:42: Thread 0: finishing\n",
      "13:41:42: Thread 2: finishing\n",
      "13:41:42: Thread 1: finishing\n",
      "13:41:42: thread 0 done\n",
      "13:41:42: before joining thread 1\n",
      "13:41:42: thread 1 done\n",
      "13:41:42: before joining thread 2\n",
      "13:41:42: thread 2 done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "\n",
    "    threads = list()\n",
    "    logging.info(\"START CREATING THREADS\")\n",
    "    for index in range(3):\n",
    "        logging.info(\"create and start thread \" + str(index))\n",
    "        x = threading.Thread(target=thread_function, args=(index,))\n",
    "        threads.append(x)\n",
    "        x.start()\n",
    "    logging.info(\"all threads started\")\n",
    "\n",
    "    logging.info(\"ENDING THE THREADS\")\n",
    "    for index, thread in enumerate(threads):\n",
    "        logging.info(\"before joining thread \" + str(index))\n",
    "        thread.join()\n",
    "        logging.info(\"thread \" + str(index) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb46a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eeb796",
   "metadata": {},
   "source": [
    "## Use of TheadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02e4e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:41:45: Thread 0: starting\n",
      "13:41:45: Thread 1: starting\n",
      "13:41:45: Thread 2: starting\n",
      "13:41:45: Thread 1: starting\n",
      "13:41:45: Thread 2: starting\n",
      "13:41:47: Thread 1: finishing\n",
      "13:41:47: Thread 0: finishing\n",
      "13:41:47: Thread 2: finishing\n",
      "13:41:47: Thread 1: finishing\n",
      "13:41:47: Thread 0: finishing\n",
      "13:41:47: Thread 2: finishing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "    executor.map(thread_function, range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3611b6a2",
   "metadata": {},
   "source": [
    "## Basic thread program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c9a36f",
   "metadata": {},
   "source": [
    "#### Function working without thread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f26835e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait started\n",
      "wait done\n",
      "wait started\n",
      "wait done\n",
      "wait started\n",
      "wait done\n",
      "Finished in 2.01 seconds\n",
      "wait done\n",
      "Finished in 2.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait():\n",
    "    print(\"wait started\")\n",
    "    time.sleep(1)\n",
    "    print(\"wait done\")\n",
    "\n",
    "wait()\n",
    "wait()\n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba08ed",
   "metadata": {},
   "source": [
    "#### Function with thread\n",
    "* without loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3f26bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait started\n",
      "wait started\n",
      "wait done\n",
      "wait done\n",
      "Finished in 1.0 seconds\n",
      "wait done\n",
      "wait done\n",
      "Finished in 1.0 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait():\n",
    "    print(\"wait started\")\n",
    "    time.sleep(1)\n",
    "    print(\"wait done\")\n",
    "\n",
    "t1=threading.Thread(target=wait)\n",
    "t2=threading.Thread(target=wait)\n",
    "t1.start()\n",
    "t2.start()\n",
    "t1.join()\n",
    "t2.join()   \n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a72cc3",
   "metadata": {},
   "source": [
    "* thread management in loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7bbc3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait of 1.5 started\n",
      "wait donewait done\n",
      "\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "Finished in 1.51 seconds\n",
      "wait donewait done\n",
      "\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "wait done\n",
      "Finished in 1.51 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait(seconds):\n",
    "    print(f\"wait of {seconds} started\")\n",
    "    time.sleep(seconds)\n",
    "    print(\"wait done\")\n",
    "\n",
    "threadss=[]\n",
    "for _ in range(10):\n",
    "    t=threading.Thread(target=wait,args=[1.5])\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "    \n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c6a76",
   "metadata": {},
   "source": [
    "* Using ThreadpoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d43b257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait of 1 startedwait of 2 started\n",
      "\n",
      "wait of 3 started\n",
      "<bound method Future.result of <Future at 0x105ed3340 state=running>>\n",
      "<bound method Future.result of <Future at 0x105ed0100 state=running>>\n",
      "<bound method Future.result of <Future at 0x105ed3e20 state=running>>\n",
      "Finished in 3.01 seconds\n",
      "Finished in 3.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait(seconds):\n",
    "    print(f\"wait of {seconds} started\")\n",
    "    time.sleep(seconds)\n",
    "    return 'done waiting'\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as ex:\n",
    "    t1 = ex.submit(wait,1)\n",
    "    t2 = ex.submit(wait,2)\n",
    "    t3 = ex.submit(wait,3)\n",
    "    print(t1.result)\n",
    "    print(t2.result)\n",
    "    print(t3.result)\n",
    "\n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f245cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait of 1 startedwait of 1 started\n",
      "\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "wait of 1 started\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "Finished in 1.01 seconds\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "done waiting\n",
      "Finished in 1.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait(seconds):\n",
    "    print(f\"wait of {seconds} started\")\n",
    "    time.sleep(seconds)\n",
    "    return 'done waiting'\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as ex:\n",
    "    result=[]\n",
    "    for _ in range(10):\n",
    "        result.append(ex.submit(wait,1))\n",
    "    \n",
    "    for f in concurrent.futures.as_completed(result):\n",
    "        print(f.result())\n",
    "\n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdb51989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait of 5 started\n",
      "wait of 4 started\n",
      "wait of 3 started\n",
      "wait of 2 started\n",
      "wait of 1 started\n",
      "done waiting for 5 sec\n",
      "done waiting for 4 sec\n",
      "done waiting for 3 sec\n",
      "done waiting for 2 sec\n",
      "done waiting for 1 sec\n",
      "Finished in 5.01 seconds\n",
      "done waiting for 5 sec\n",
      "done waiting for 4 sec\n",
      "done waiting for 3 sec\n",
      "done waiting for 2 sec\n",
      "done waiting for 1 sec\n",
      "Finished in 5.01 seconds\n"
     ]
    }
   ],
   "source": [
    "start=time.perf_counter()\n",
    "\n",
    "def wait(seconds):\n",
    "    print(f\"wait of {seconds} started\")\n",
    "    time.sleep(seconds)\n",
    "    return f'done waiting for {seconds} sec'\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as ex:\n",
    "    sec=[5,4,3,2,1]\n",
    "    result=ex.map(wait,sec)\n",
    "\n",
    "    for res in result:\n",
    "        print(res)\n",
    "\n",
    "    \n",
    "\n",
    "finish=time.perf_counter()\n",
    "total= round(finish - start,2)\n",
    "\n",
    "print(f\"Finished in {total} seconds\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdaec6",
   "metadata": {},
   "source": [
    "# Real World Example: Downloading Images from Unsplash\n",
    "\n",
    "Let's see how threading can speed up downloading multiple images from Unsplash API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f25d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m264.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m264.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/162.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m  Downloading certifi-2025.7.14-py3-none-any.whl (162 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m330.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.7/162.7 kB\u001b[0m \u001b[31m330.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/201.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mCollecting charset_normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.2-cp310-cp310-macosx_10_9_universal2.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m661.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m661.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.7.14 charset_normalizer-3.4.2 idna-3.10 requests-2.32.4 urllib3-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Successfully installed certifi-2025.7.14 charset_normalizer-3.4.2 idna-3.10 requests-2.32.4 urllib3-2.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "155fb17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directory for downloaded images\n",
    "os.makedirs(\"downloaded_images\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_info):\n",
    "    \"\"\"Download a single image\"\"\"\n",
    "    url, filename = image_info\n",
    "    \n",
    "    print(f\"Started downloading: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Disable SSL verification to avoid certificate issues\n",
    "        response = requests.get(url, timeout=30, verify=False)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the image\n",
    "        file_path = f\"downloaded_images/{filename}\"\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"✅ Downloaded: {filename} ({len(response.content)} bytes)\")\n",
    "        return f\"Success: {filename}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to download {filename}: {str(e)}\")\n",
    "        return f\"Failed: {filename} - {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fcc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to download 10 images...\n"
     ]
    }
   ],
   "source": [
    "# Alternative image URLs that should work better\n",
    "# Using picsum.photos which is more reliable\n",
    "image_urls = [\n",
    "    (\"https://picsum.photos/800/600?random=1\", \"nature_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=2\", \"city_1.jpg\"), \n",
    "    (\"https://picsum.photos/800/600?random=3\", \"tech_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=4\", \"animals_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=5\", \"food_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=6\", \"travel_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=7\", \"arch_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=8\", \"ocean_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=9\", \"mountain_1.jpg\"),\n",
    "    (\"https://picsum.photos/800/600?random=10\", \"space_1.jpg\")\n",
    "]\n",
    "\n",
    "print(f\"Ready to download {len(image_urls)} images...\")\n",
    "print(\"Using picsum.photos for reliable image downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746d5353",
   "metadata": {},
   "source": [
    "## Method 1: Sequential Download (No Threading)\n",
    "Download images one by one - slow but simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60e5e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Starting SEQUENTIAL downloads...\n",
      "--------------------------------------------------\n",
      "Started downloading: nature_1.jpg\n",
      "❌ Failed to download nature_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?nature (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: city_1.jpg\n",
      "❌ Failed to download nature_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?nature (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: city_1.jpg\n",
      "❌ Failed to download city_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?city (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: tech_1.jpg\n",
      "❌ Failed to download city_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?city (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: tech_1.jpg\n",
      "❌ Failed to download tech_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?technology (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: animals_1.jpg\n",
      "❌ Failed to download tech_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?technology (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: animals_1.jpg\n",
      "❌ Failed to download animals_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?animals (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: food_1.jpg\n",
      "❌ Failed to download animals_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?animals (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: food_1.jpg\n",
      "❌ Failed to download food_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?food (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: travel_1.jpg\n",
      "❌ Failed to download food_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?food (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: travel_1.jpg\n",
      "❌ Failed to download travel_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?travel (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: arch_1.jpg\n",
      "❌ Failed to download travel_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?travel (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: arch_1.jpg\n",
      "❌ Failed to download arch_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?architecture (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: ocean_1.jpg\n",
      "❌ Failed to download arch_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?architecture (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: ocean_1.jpg\n",
      "❌ Failed to download ocean_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?ocean (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: mountain_1.jpg\n",
      "❌ Failed to download ocean_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?ocean (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: mountain_1.jpg\n",
      "❌ Failed to download mountain_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?mountains (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: space_1.jpg\n",
      "❌ Failed to download mountain_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?mountains (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "Started downloading: space_1.jpg\n",
      "❌ Failed to download space_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?space (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "--------------------------------------------------\n",
      " Sequential download completed in 6.36 seconds\n",
      " Downloaded 0 images successfully\n",
      "❌ Failed to download space_1.jpg: HTTPSConnectionPool(host='source.unsplash.com', port=443): Max retries exceeded with url: /800x600/?space (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1007)')))\n",
      "--------------------------------------------------\n",
      " Sequential download completed in 6.36 seconds\n",
      " Downloaded 0 images successfully\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "print(\" Starting SEQUENTIAL downloads...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "results = []\n",
    "for image_info in image_urls:\n",
    "    result = download_image(image_info)\n",
    "    results.append(result)\n",
    "\n",
    "finish = time.perf_counter()\n",
    "total = round(finish - start, 2)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(f\" Sequential download completed in {total} seconds\")\n",
    "print(f\" Downloaded {len([r for r in results if 'Success' in r])} images successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd82bc5",
   "metadata": {},
   "source": [
    "## Method 2: Threaded Download using ThreadPoolExecutor\n",
    "Download images concurrently - much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768b886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "print(\"🚀 Starting THREADED downloads...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Submit all download tasks\n",
    "    future_to_image = {executor.submit(download_image, img_info): img_info for img_info in image_urls}\n",
    "    \n",
    "    results = []\n",
    "    for future in concurrent.futures.as_completed(future_to_image):\n",
    "        result = future.result()\n",
    "        results.append(result)\n",
    "\n",
    "finish = time.perf_counter()\n",
    "total = round(finish - start, 2)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"🚀 Threaded download completed in {total} seconds\")\n",
    "print(f\"📊 Downloaded {len([r for r in results if 'Success' in r])} images successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b3f0db",
   "metadata": {},
   "source": [
    "## Method 3: Using executor.map() - Cleaner Syntax\n",
    "Same threading performance but simpler code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a94918",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "print(\"⚡ Starting THREADED downloads with executor.map()...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Use map() for cleaner syntax - results come back in order\n",
    "    results = list(executor.map(download_image, image_urls))\n",
    "\n",
    "finish = time.perf_counter()\n",
    "total = round(finish - start, 2)\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"⚡ executor.map() download completed in {total} seconds\")\n",
    "print(f\"📊 Downloaded {len([r for r in results if 'Success' in r])} images successfully\")\n",
    "print(f\"📁 Check the 'downloaded_images' folder for your images!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7455cb",
   "metadata": {},
   "source": [
    "## Key Learnings from This Real-World Example:\n",
    "\n",
    "### 🔥 **Performance Improvement**\n",
    "- **Sequential**: Downloads one image at a time (slow)\n",
    "- **Threaded**: Downloads multiple images simultaneously (much faster!)\n",
    "- **Speed increase**: Often 3-5x faster for I/O operations like downloads\n",
    "\n",
    "### 🛠️ **When to Use Threading**\n",
    "- **Perfect for**: Network requests, file downloads, API calls, database queries\n",
    "- **Not good for**: CPU-intensive tasks (use multiprocessing instead)\n",
    "\n",
    "### 💡 **Threading Methods Comparison**\n",
    "1. **`executor.submit()`** + `as_completed()`: Best when you need results as they finish\n",
    "2. **`executor.map()`**: Cleanest syntax, results in order, perfect for simple cases\n",
    "3. **Manual threading**: More control but more complex code\n",
    "\n",
    "### 🎯 **Real-World Applications**\n",
    "- Downloading multiple files\n",
    "- Making multiple API calls\n",
    "- Processing multiple database queries  \n",
    "- Web scraping multiple pages\n",
    "- Uploading multiple files to cloud storage\n",
    "\n",
    "*Threading shines when your program spends time waiting for external resources!*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
